{
  
    
        "post0": {
            "title": "Title",
            "content": "Juliette Cornet 03/14/2022 . Sentiment Analysis of Taylor Swift&#39;s Albums . Part 1: Introduction . As a comparative literature major, close-reading textual analysis is something I&#39;m particularly interested in. Therefore, when we started doing textual analysis via data science, I knew this was what I wanted to do my final project on. Considering Taylor Swift has recently been making a comeback, I thought it would intersting to look into her music and her persona which is where I got the inspiration for this project. . Taylor swift is known for constantly re-inventing herself. Her ever-changing persona is known to be split up into different &quot;eras.&quot; While this is very apparent in the changes of her physial appearance and in her music videos and concert performances, I am curious to see if these shifts are identifiable from the lyrics in all her albums alone.Through data and textual analysis, I want to see if certain trends in her lyrics give us insight into the different changes she has undergone over the years. Therefore, through a combination of data science and textual analysis, is it possible to indenity different trends in Taylor Swift&#39;s lyrics throughout her albums? . Part 2: Methods . For my analysis, I will be using a datasetfrom Github that has every lyric from every song from her first eight albums. Linked here: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-09-29/taylor_swift_lyrics.csv . For my research, I will be analysing the word frequency across the different albums. That will invovle analyzing the 20 most frequently used lyrics for each of her eight albums. I will not be analysing the lyrics of individual songs but instead the combined lyrics per album to get a more overarching sense of her evolution as an artist. . To narrow my search, I will then look at the 10 most frequently used nouns per album to see if by narrowing my search, it is more effective in identifying certain themes. . Finally, I will be doing some sentiment analysis by looking at the polarity scores of eahc of her albums to idenfity more positive or negative tones in the hopes that it gives some insight into tonal changes throughout her career. . For the bulk of my porject, I will be using Pandas to aid in the importing and processing of the data, NLTK to conduct the word freuqnecy and sentiment analysis and finally Matplotlib for the data visualizations used to accompany my research. . Let&#39;s begin by looking at the data to get a better sense of what we&#39;re working with. . import pandas as pd . df . Artist Album Title Lyrics . 0 Taylor Swift | Taylor Swift | Tim McGraw | He said the way my blue eyes shinx nPut those ... | . 1 Taylor Swift | Taylor Swift | Picture to Burn | State the obvious, I didn&#39;t get my perfect fan... | . 2 Taylor Swift | Taylor Swift | Teardrops on my Guitar | Drew looks at me, nI fake a smile so he won&#39;t ... | . 3 Taylor Swift | Taylor Swift | A Place in This World | I don&#39;t know what I want, so don&#39;t ask me n&#39;Ca... | . 4 Taylor Swift | Taylor Swift | Cold As You | You have a way of coming easily to me nAnd whe... | . ... ... | ... | ... | ... | . 127 Taylor Swift | folklore | mad woman | What did you think I&#39;d say to that? nDoes a sc... | . 128 Taylor Swift | folklore | epiphany | Keep your helmet nKeep your life, son nJust a ... | . 129 Taylor Swift | folklore | betty | Betty, I won&#39;t make assumptions about why you ... | . 130 Taylor Swift | folklore | peace | Our coming of age has come and gone nSuddenly ... | . 131 Taylor Swift | folklore | hoax | My only one nMy smoking gun nMy eclipsed sun n... | . 132 rows × 4 columns . Part 3: Results . Cleaning up the data so it&#39;s easier to use . As you can see, it is split up into 4 different columns: Artist, Album, Title, Lyrics. Since I want to be doing a textual analysis of how her lyrics have changed between her albums, the two columns that are important to my research are the Album column and the Lyrics columns. For my analysis, I want to seperate all the albums and add combine the lyrics from all songs under one album title to make to text analysis procress easier. Therefore, below I turn the lyrics into lists based on the album they correspond to. I do this using a for loop. . taylor_swift = [] fearless = [] speak_now = [] red = [] album_1989 = [] reputation = [] lover = [] folklore = [] num_rows = len(df) for i in range(num_rows): if df.loc[i,&quot;Album&quot;] == &quot;Taylor Swift &quot;: taylor_swift.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;Fearless&quot;: fearless.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;Speak Now &quot;: speak_now.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;Red&quot;: red.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;1989&quot;: album_1989.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;reputation &quot;: reputation.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;Lover &quot;: lover.append(df.loc[i,&quot;Lyrics&quot;]) elif df.loc[i,&quot;Album&quot;] == &quot;folklore &quot;: folklore.append(df.loc[i,&quot;Lyrics&quot;]) . I will now tokenize and removing stopwords from each of the album lists. . import nltk from nltk.tokenize import word_tokenize, sent_tokenize from nltk.corpus import stopwords from string import punctuation nltk.download(&#39;stopwords&#39;) from nltk.probability import FreqDist import matplotlib.pyplot as plt import seaborn as sns from wordcloud import WordCloud import multidict as multidict import numpy as np import os import re from os import path . [nltk_data] Downloading package stopwords to /home/jovyan/nltk_data... [nltk_data] Package stopwords is already up-to-date! . taylor_swift_album = &quot; &quot;.join(taylor_swift) fearless_album = &quot; &quot;.join(fearless) red_album = &quot; &quot;.join(red) album_1989_album = &quot; &quot;.join(album_1989) reputation_album = &quot; &quot;.join(reputation) lover_album = &quot; &quot;.join(lover) folklore_album = &quot; &quot;.join(folklore) speak_now_album = &quot; &quot;.join(speak_now) . #taylor_swift ts_sentences = sent_tokenize(taylor_swift_album) ts_words = word_tokenize(taylor_swift_album.lower()) #fearless f_sentences = sent_tokenize(fearless_album) f_words = word_tokenize(fearless_album.lower()) #speaknow s_sentences = sent_tokenize(speak_now_album) s_words = word_tokenize(speak_now_album.lower()) #red r_sentences = sent_tokenize(red_album) r_words = word_tokenize(red_album.lower()) #1989 nine_sentences = sent_tokenize(album_1989_album) nine_words = word_tokenize(album_1989_album.lower()) #reputation rep_sentences = sent_tokenize(reputation_album) rep_words = word_tokenize(reputation_album.lower()) #lover l_sentences = sent_tokenize(lover_album) l_words = word_tokenize(lover_album.lower()) #folklore fo_sentences = sent_tokenize(folklore_album) fo_words = word_tokenize(folklore_album.lower()) . extrastopwords = [&#39;``&#39;, &quot;&#39;s&quot;, &quot;&#39;&#39;&quot;, &#39;``&#39;,&quot;n&#39;t&quot;, &quot;&#39;m&quot;, &#39;oh&#39;,&quot;&#39;ll&quot;,&#39;mmm&#39;,&quot;&#39;wo&quot;,&quot;&#39;re&#39;&quot;, &#39;ai&#39;, &quot;&#39;re&quot;,&quot;&#39;ve&quot;, &#39;na&#39;,&#39;wan&#39;,&#39;would&#39;,&#39;said&#39;, &quot;&#39;cause&quot;, &quot;&#39;d&quot;, &quot;oh-oh&quot;, &quot;ha&quot;, &quot;ooh&quot;, &quot;ca&quot;, &quot;yeah&quot;, &quot;gon&quot;, &quot;get&quot;] myStopWords = list(punctuation) + stopwords.words(&#39;english&#39;) + extrastopwords . tsNoStopWords = [w for w in ts_words if w not in myStopWords] fNoStopWords = [w for w in f_words if w not in myStopWords] sNoStopWords = [w for w in s_words if w not in myStopWords] rNoStopWords = [w for w in r_words if w not in myStopWords] nineNoStopWords = [w for w in nine_words if w not in myStopWords] repNoStopWords = [w for w in rep_words if w not in myStopWords] lNoStopWords = [w for w in l_words if w not in myStopWords] foNoStopWords = [w for w in fo_words if w not in myStopWords] . Word Frequency Analysis . Now that I&#39;ve cleaned up the data by tokenizing the lyrics and removing the stopwords, I can begin analyzing her lyrics per album. I&#39;ll begin by first looking at the most frequently used words per album to see if we can being identifying differences. . Taylor Swift . freq_ts = FreqDist(tsNoStopWords) . for i in sorted(freq_ts, key=freq_ts.get, reverse=True)[:20]: print(i,freq_ts[i]) . know 35 think 26 never 25 back 23 love 20 see 18 one 17 like 17 beautiful 17 way 15 song 15 baby 15 time 14 take 14 hope 13 still 13 could 12 let 12 everything 12 got 12 . ts_fdist = FreqDist(tsNoStopWords).most_common(20) # Creating barplot ts_fdist = pd.Series(dict(ts_fdist)) fig, ax = plt.subplots(figsize=(10,10)) all_plot = sns.barplot(x=ts_fdist.index, y=ts_fdist.values, ax=ax) plt.xticks(rotation=30); # Set title ax.set_title(&quot;Taylor Swift 20 Most Frequent Words&quot;) # adding labels ax.set_xlabel(&#39;Words&#39;) ax.set_ylabel(&#39;Frequency&#39;) . Text(0, 0.5, &#39;Frequency&#39;) . wcloud = WordCloud(background_color=&quot;white&quot;).generate_from_frequencies(ts_fdist) plt.imshow(wcloud, interpolation=&quot;bilinear&quot;) plt.axis(&quot;off&quot;) (-0.5, 399.5, 199.5, -0.5) title = &quot;worddy cliud&quot; plt.title(&#39;Taylor Swift Word Cloud&#39;) plt.show() . Based on the most frequently used lyrics from her first album, the tone appears hopeful and romantic based on the frequent use of words like &quot;love&quot;, &quot;hope&quot;, &quot;beauitful&quot;, &quot;song&quot; and &quot;baby&quot;. Accurate to Taylor&#39;s young persona at the time which was a country girl who wrote love songs in her bedroom. . Fearless . know 72 like 41 come 41 never 31 say 30 feel 27 see 26 time 25 baby 25 one 24 back 24 way 23 love 23 fall 22 could 22 got 20 tell 20 help 20 night 18 little 16 . Text(0.5, 1.0, &#39;Fearless 20 Most Frequent Words&#39;) . For Fearless, there are a lot of recurring words from her previous album that she still enjoys using: &quot;know&quot;, &quot;never&quot;, &quot;like&quot;, &quot;baby&quot;. However, the tone of this album feels a little less hopeful than the last one with words like &quot;fall&quot; and &quot;night&quot;. However, romantic undertones are present with &quot;love&quot;, &quot;baby&quot; and &quot;feel&quot;. . Speak Now . back 63 like 58 know 42 come 39 ever 35 go 33 never 32 see 32 say 30 time 29 love 23 around 23 away 22 still 22 mean 22 mind 21 could 20 grow 20 got 19 think 18 . Text(0, 0.5, &#39;Frequency&#39;) . Once again, Taylor&#39;s frequently used words &quot;like&quot; and &quot;know&quot; are once again in the frequency list. However, there seems to be come growth with words like &quot;grow&quot; and &quot;away&quot; and &quot;back&quot;. The word &quot;love&quot;&#39;s frequency is also losing stamina. In the first album, &quot;love&quot; fell into the yellow part of the gradient on the bar plot which made it one of the most frequently used words. However, in the last two albums, &quot;love&quot; has fallen into the blue part of the gradient on the barplot meaning that she is using it less. Therefore, romantic feelings are still present but less so than originally. . Red . like 92 know 83 time 66 never 53 red 46 back 43 ever 35 one 33 stay 32 trouble 32 last 32 got 30 asking 25 home 25 everybody 25 love 24 better 24 tell 23 think 23 knows 23 . Text(0, 0.5, &#39;Frequency&#39;) . Once again, &quot;know&quot; and &quot;like&quot; are at the top of this list. However, it is interesing to see that &quot;red&quot;–which is the title of the album–is also a frequently used word here. This is the first time this has happened in her albums. Words like &quot;back&quot;, &quot;home&quot;, &quot;time&quot; and &quot;everybody&quot; make it seem like there is a return to her roots. However, the frequency of the word &quot;trouble&quot; is the first time a word with an obviously negative connotation has entered word frequency top 20 list. Interesting to see that it is used even more than &quot;love&quot;. Seems that romance has been replaced with some turmoil. This is during the era that Taylor started growing up in the eyes of the public and wearing red lipstick. The negative tone of &quot;trouble&quot; could indicate she is asserting herself not only in her physical appearance but her lyrics too. . 1989 . wish 85 love 84 shake 70 yet 65 got 55 new 45 back 44 like 42 baby 41 never 39 go 39 woods 38 clear 37 know 36 say 34 could 33 stay 32 york 30 welcome 29 girl 25 . Text(0, 0.5, &#39;Frequency&#39;) . This albums seems to mark a shift. &quot;Love&quot; is suddently right near the top alongside &quot;wish&quot; replacing &quot;like&quot; and &quot;know&quot; that are always near the top. Words like &quot;shake&quot;, &quot;wish&quot;, &quot;love&quot; and &quot;welcome&quot; imply a more fun and lively spirit in her music. Also interesting to note that &quot;new&quot; &quot;york&quot; and &quot;woods&quot; make the frequency list since it clearly shows that New York, a place, plays an important role in her album. . Reputation . like 51 made 51 look 46 want 38 baby 37 time 34 know 32 bad 29 never 27 take 27 say 27 first 26 one 26 call 26 could 26 good 24 things 23 hands 23 got 22 getaway 21 . Text(0, 0.5, &#39;Frequency&#39;) . Reputation is an interesting album to compare to its predecessor since &quot;love&quot; is completely removed from the list. Instead, &quot;like&quot; and &quot;know&quot; are back at the top. There also seems to be a contrast between &quot;good&quot; and &quot;bad&quot;, with bad winning since it is used more frequently. Words likes &quot;take&quot; and &quot;want&quot; also imply a sort of assertiveness. Her public persona was much tougher during this era than ever before. . Lover . like 67 want 49 love 44 one 43 never 43 see 42 daylight 40 know 38 right 28 go 27 man 27 baby 26 say 23 street 23 think 22 could 21 got 20 still 20 walk 19 need 19 . Text(0, 0.5, &#39;Frequency&#39;) . Lover marks another shift. Romantic feelings return with &quot;love&quot; being back on the list and high up. Interesting to see that &quot;daylight&quot; is high up on the list since it not only gives a period of time but is also a physical attribute. Daylight is often associated with brightness and happiness. Also intersting to see that &quot;street&quot; makes the list since it&#39;s a noun to describe a place that is pretty common and vague. I remember this album not doing very well. . Folklore . never 44 know 42 time 38 like 38 think 21 one 19 knew 18 gave 17 love 17 around 16 could 15 see 15 still 15 back 13 mad 13 come 12 seen 12 give 12 showed 11 woman 11 . Text(0, 0.5, &#39;Frequency&#39;) . Folklore doesn&#39;t reveal too much since commonly popular words Taylor uses like &quot;never&quot;, &quot;know&quot;, &quot;like&quot;, &quot;time&quot; and &quot;think&quot; are at the top and are not the most revealing words. However, two words that stand out are &quot;mad&quot; and &quot;woman&quot; since they don&#39;t appear on any of the other lists. . Overall, words frequency does give us some insight into changes in her lyrics, especially when words frequently used throughout several albums don’t appear in some of them (like “time” and “love”). Nevertheless, I realized the most helpful words to analyze in the word frequency were the nouns since they gave a sense of theme better than verbs or adjectives. Therefore, to narrow my research, looking at noun frequency in her albums might help us get a better sense of changes in her discography. . Noun Frequency Analysis . In this section, in order to narrow my analysis, I will concentrating on the 10 most frequent nouns in each of her albums to see if that gives us a better sense of a shift in tone and style throughout her albums. . To do so, I identify all the nouns which I can achieve by tagging the parts of speech using pos_tag. . #taylorswift tstagged = nltk.pos_tag(tsNoStopWords) #Fearless ftagged = nltk.pos_tag(fNoStopWords) #speaknow stagged = nltk.pos_tag(sNoStopWords) #red rtagged = nltk.pos_tag(rNoStopWords) #1989 ninetagged = nltk.pos_tag(nineNoStopWords) #reputation reptagged = nltk.pos_tag(repNoStopWords) #lover ltagged = nltk.pos_tag(lNoStopWords) #folklore fotagged = nltk.pos_tag(foNoStopWords) . Taylor Swift . t_nouns = [] for sentence in tslist: for word, pos in sentence: if (pos == &#39;NN&#39; or pos == &#39;NNS&#39;): t_nouns.append(word) . tsfreq = FreqDist(t_nouns) for i in sorted(tsfreq, key=tsfreq.get, reverse=True)[:10]: print(i,tsfreq[i]) . way 15 time 14 love 14 baby 14 everything 12 eyes 11 song 10 heart 10 home 9 break 8 . Text(0, 0.5, &#39;Frequency&#39;) . Nouns are romantic: &quot;Love&quot;, &quot;baby&quot; and &quot;heart. This love could be due to a breakup (&quot;break&quot;) or could be family love (&quot;home&quot;). This makes sense considering her first album was a country album where themes of love and family are common. . Fearless . time 25 way 23 baby 21 night 18 fall 17 help 16 jump 15 feel 15 everything 14 things 13 . Text(0, 0.5, &#39;Frequency&#39;) . Interesting that &quot;love&quot; isn&#39;t on this list. &quot;Time&quot; and &quot;way&quot; remain at the top of the list. Ultimately, no huge tonal differences other than the love and romance being a bit on the back burner which is odd considering I know this album to be pretty love ballad heavy. . Speak Now . time 29 mind 20 something 15 things 14 eyes 14 nothing 14 day 14 life 13 night 13 way 12 . Text(0, 0.5, &#39;Frequency&#39;) . &quot;Time&quot; is the most used word followed by &quot;mind&quot;. &quot;Night&quot; is also a recurring word here. No nounds that stand out in comparision to her previous albums. . Red . time 66 trouble 32 everybody 25 home 22 everything 19 night 17 starlight 16 love 15 name 14 look 14 . Text(0, 0.5, &#39;Frequency&#39;) . &quot;Time&quot; is the most used word by a landslide followed up by &quot;trouble&quot; which I would consider a shift since Taylor up until this point strayed from negative words as mentioned during the word frequency analysis. &quot;Starlight&quot; and &quot;night&quot; also imply a shift. . 1989 . love 65 baby 35 york 30 shake 24 woods 20 wonderland 19 blood 16 hey 15 places 14 girl 13 . Text(0, 0.5, &#39;Frequency&#39;) . 1989 is unexpected. While the album is known for being more upbeat and fun since it&#39;s her first officially released pop album, the use of the word &quot;blood&quot; was unexpected since the word itself is quite gory. Furthermore, words like &quot;wonderland&quot; and &quot;woods&quot; give a whimsical appearance. The fact that &quot;time&quot; (which appears to be Taylor&#39;s favorite noun) does not appear in this album seems signifcant. . Reputation . look 41 time 34 baby 26 call 25 things 23 hands 21 car 21 getaway 19 endgame 14 nothing 13 . Text(0, 0.5, &#39;Frequency&#39;) . Reputation is an important album since it was her comeback album after being &quot;cancelled&quot; in the media after her rift with Kim Kardahsian and Kanye West. Therefore, I was anticipating a noticeable change in her lyrics. There is nothing here that really indicates a shift other than words like &quot;endgame&quot; and &quot;car&quot;. &quot;Endgame&quot; does feel calculated. . Lover . man 27 daylight 25 street 22 baby 21 night 17 home 16 boy 13 things 13 love 10 nobody 10 . Text(0, 0.5, &#39;Frequency&#39;) . The fact that &quot;man&quot; and &quot;boy&quot; are both in the top ten nouns used in this album is interesting, especially since is right at the top. Could in a reference to a male lover since &quot;lover&quot; is the title of the album. &quot;Daylight&quot; also contrasts the use of frequency of &quot;night&quot; in some of her other albums. Definite changes happening here. . Folklore . time 38 woman 11 everything 11 signs 10 heart 9 thing 8 nothing 8 get 8 things 8 call 8 . Text(0, 0.5, &#39;Frequency&#39;) . Folkore appears to be a return to her roots with the reappearance of &quot;time&quot;. Also distinguishes itself from the previous album Lover with &quot;woman&quot; now falling into the most frequently used list to oppose &quot;man&quot; and &quot;boy&quot;. . Based the noun frequency output, &quot;time&quot; and &quot;love&quot; seem to be recurring words throughout her entire discography. While not obvious, there appear to be a few shifts apparent when just looking at her nouns. In fact, we can loosely split her albums into 3 &quot;trends&quot; : . Younger, romantic (key nouns: &quot;time&quot;, &quot;way&quot;, &quot;home&quot;, &quot;night&quot;: Taylor Swift, Fearless, Speak Now and Red) . | Whimsical, unexpected, new for Taylor (key nouns: &quot;blood&quot;, &quot;woods&quot;, &quot;wonderland&quot;): 1989 . | Urban, modern, return to her roots (key nouns: &quot;car&quot;, &quot;street&quot;, &quot;time&quot;, &quot;home&quot;, &quot;love&quot;): Reputation, Lover, Folklore. . | . Overall, analysing word and noun frequency did allow us to indentify some shifts in her lyrics that coincide with her changing persona over the years. I&#39;m curious to see whether this is the case using sentiment analysis. . Sentiment Analysis . In an attmept to indentify tonal differences in her albums, we will use sentiment analysis to help identify more postive or negative tones in her music. To do so, we will be using Vader which provides sentiment scores on textual data. . import nltk from nltk.sentiment import vader nltk.download(&#39;vader_lexicon&#39;) . [nltk_data] Downloading package vader_lexicon to [nltk_data] /home/jovyan/nltk_data... [nltk_data] Package vader_lexicon is already up-to-date! . True . sia = vader.SentimentIntensityAnalyzer() . sia.polarity_scores(taylor_swift_album) . {&#39;neg&#39;: 0.102, &#39;neu&#39;: 0.731, &#39;pos&#39;: 0.166, &#39;compound&#39;: 0.9999} . sia.polarity_scores(fearless_album) . {&#39;neg&#39;: 0.088, &#39;neu&#39;: 0.751, &#39;pos&#39;: 0.161, &#39;compound&#39;: 1.0} . sia.polarity_scores(speak_now_album) . {&#39;neg&#39;: 0.087, &#39;neu&#39;: 0.762, &#39;pos&#39;: 0.152, &#39;compound&#39;: 0.9999} . sia.polarity_scores(red_album) . {&#39;neg&#39;: 0.097, &#39;neu&#39;: 0.719, &#39;pos&#39;: 0.184, &#39;compound&#39;: 1.0} . sia.polarity_scores(album_1989_album) . {&#39;neg&#39;: 0.148, &#39;neu&#39;: 0.652, &#39;pos&#39;: 0.2, &#39;compound&#39;: 0.9999} . sia.polarity_scores(reputation_album) . {&#39;neg&#39;: 0.098, &#39;neu&#39;: 0.736, &#39;pos&#39;: 0.166, &#39;compound&#39;: 0.9999} . sia.polarity_scores(lover_album) . {&#39;neg&#39;: 0.131, &#39;neu&#39;: 0.684, &#39;pos&#39;: 0.184, &#39;compound&#39;: 0.9999} . sia.polarity_scores(folklore_album) . {&#39;neg&#39;: 0.127, &#39;neu&#39;: 0.732, &#39;pos&#39;: 0.141, &#39;compound&#39;: 0.9989} . data = {&#39;Album&#39;: [&#39;Taylor Swift&#39;, &#39;Fearless&#39;, &#39;Speak Now&#39;, &#39;Red&#39;, &#39;1989&#39;, &#39;Reputation&#39;, &#39;Lover&#39;, &#39;Folklore&#39;], &#39;Negative Score&#39;: [0.102, 0.088, 0.087, 0.097, 0.148, 0.098, 0.131, 0.127], &#39;Neutral Score&#39;: [0.731, 0.751, 0.762, 0.719, 0.652, 0.736, 0.684, 0.732], &#39;Positive Score&#39;: [0.166, 0.161, 0.152, 0.184, 0.2, 0.166, 0.184, 0.141], &#39;Compound&#39;: [0.9999, 1, 0.9999, 1, 0.9999, 0.9999, 0.9999, 0.9989]} df1 = pd.DataFrame(data) print(df1) . Album Negative Score Neutral Score Positive Score Compound 0 Taylor Swift 0.102 0.731 0.166 0.9999 1 Fearless 0.088 0.751 0.161 1.0000 2 Speak Now 0.087 0.762 0.152 0.9999 3 Red 0.097 0.719 0.184 1.0000 4 1989 0.148 0.652 0.200 0.9999 5 Reputation 0.098 0.736 0.166 0.9999 6 Lover 0.131 0.684 0.184 0.9999 7 Folklore 0.127 0.732 0.141 0.9989 . ax = plt.gca() df1.plot( x = &#39;Album&#39; , y = &#39;Negative Score&#39;, ax = ax, color = &#39;red&#39;, figsize=(10, 5), title = &#39;Taylor Swift Album Polarity Evolution&#39;) df1.plot( x = &#39;Album&#39; , y = &#39;Neutral Score&#39; , ax = ax, color = &#39;yellow&#39;, figsize=(10,5)) df1.plot( x = &#39;Album&#39; , y = &#39;Positive Score&#39; , ax = ax, color= &#39;blue&#39;, figsize=(10, 5)) df1.plot( x = &#39;Album&#39; , y = &#39;Compound&#39; , ax = ax, color = &#39;green&#39;, figsize=(10,5)) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Taylor Swift Album Polarity Evolution&#39;}, xlabel=&#39;Album&#39;&gt; . Based on the compound score of each of her albums, the general trend of her tone remains quite positive, all above a 0.9. Keep in mind that the score is from -1 to 1 with anyting below 0 negative and anything above 0 positive. The tone throughout her albums appears to be pretty similar. Overall, her albums are neutral than positive or negative based on these polarity scores. The Vader sentiment analysis of her album lyrics does not give us the best sense of tonal changes in throughout her albums. However, we can. conclude that Taylor tends to keep a more positive/neutral tone in the lyrics of her music versus negative. Considering I know many of her songs to be about heart break, I was little suprised by these findings. I defintely would have expected a slightly higher negative score, especially from the Reputation album. . Discussion . The whole point of my analysis was to see whether it was possible to pin point similar changes between Taylor Swift&#39;s ever-changing personas in the public eye and her discography, focusing exclusively on lyric analysis. . The word and noun frequency analysis proved to be more informative than the sentiment analysis. Identifying her most frequently used words and nouns per album did allow us to see Taylor go from innoncent, wishful and romantic to more assertive and then finally grounding herself back to her roots. This evolution more or less coincides with her evolution as public figure outside of her artistry. The fact that her evolution as a person develops alongside her lyrics is proof that Taylor does make her music personal and thoughtful. . However,I was disappointed by the results of the sentiment analysis since her tone remains pretty stagnant. I was defintely expecting some variation in the polarity. However, I think this simply reveals that Taylor tends to focus more on the positive than on the negative in her music. . These findings are useful in the sense they break down Taylor Swift but from a more scientific standpoint than simply listening to her music. They help us visualize themes that she has valued throughout her entire career (love, home, time) and themes she only valued during a specific album or phase (trouble, revenge, etc). Overall, these results give us a better understanding of her as a person and as an artist. .",
            "url": "https://juliettecornet.github.io/DH140-FINAL/2022/03/14/FinalProjectTaylorSwift.html",
            "relUrl": "/2022/03/14/FinalProjectTaylorSwift.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://juliettecornet.github.io/DH140-FINAL/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://juliettecornet.github.io/DH140-FINAL/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://juliettecornet.github.io/DH140-FINAL/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://juliettecornet.github.io/DH140-FINAL/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}